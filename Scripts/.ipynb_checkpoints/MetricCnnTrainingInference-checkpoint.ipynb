{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, sys\n",
    "sys.path.append('../Packages')\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import util.riemann as riemann\n",
    "import util.tensors as tensors\n",
    "import data.convert as convert\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import data, filters\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from itkwidgets import view\n",
    "from dataset import DatasetHCP\n",
    "from pde import *\n",
    "from model3D import *\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "## Network Architecture\n",
    "<img src=\"../Figures/architecture.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "## Eigen Composition\n",
    "<img src=\"../Figures/eigencomposition.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='gpu'\n",
    "\n",
    "if mode=='gpu':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # after switch device, you need restart the kernel\n",
    "    torch.cuda.set_device(1)\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_id = 111312\n",
    "input_dir = '../Brains'\n",
    "output_dir = f'../Checkpoints/{brain_id}'\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = False\n",
    "save_model = True\n",
    "print(f'resume:{resume}, save_model:{save_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_list = []\n",
    "epoch_num = 10000\n",
    "start_epoch_num = 10001\n",
    "batch_num = 1\n",
    "learning_rate = 3e-4\n",
    "blocks = [40,30,40]\n",
    "\n",
    "model = DenseED(in_channels=3, out_channels=7, \n",
    "                imsize=100,\n",
    "                blocks=blocks,\n",
    "                growth_rate=16, \n",
    "                init_features=48,\n",
    "                drop_rate=0,\n",
    "                out_activation=None,\n",
    "                upsample='nearest')\n",
    "model.train()\n",
    "if mode=='gpu':\n",
    "    model.cuda()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "dataset_id = DatasetHCP(input_dir, sample_name_list=[str(brain_id)])\n",
    "dataloader_id = DataLoader(dataset_id, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "if resume:\n",
    "    checkpoint = torch.load(f'{output_dir}/epoch_{start_epoch_num-1}_checkpoint.pth.tar')    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    with open(f'{output_dir}/loss.txt', 'a') as f:\n",
    "        f.write(f'From {start_epoch_num} to {epoch_num+start_epoch_num}\\n')\n",
    "        f.write(f'Adadelta, lr={learning_rate};\\n')\n",
    "else:\n",
    "    start_epoch_num = 0  \n",
    "    \n",
    "    with open(f'{output_dir}/loss.txt', 'w+') as f:\n",
    "        f.write(f'Architecture {blocks}\\n')\n",
    "        f.write(f'From {start_epoch_num} to {epoch_num+start_epoch_num}\\n')\n",
    "        f.write(f'Adadelta: lr={learning_rate};\\n')\n",
    "    \n",
    "print(f'Starting from iteration {start_epoch_num} to iteration {epoch_num+start_epoch_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(start_epoch_num, start_epoch_num+epoch_num)):\n",
    "    epoch_loss_id = 0\n",
    "            \n",
    "    for i, batched_id_sample in enumerate(dataloader_id):\n",
    "        input_id = batched_id_sample['vector_field']\n",
    "        input_id.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        u_pred_id = model(input_id)\n",
    "        mask = batched_id_sample['mask'].squeeze()\n",
    "        pde_loss = pde(u_pred_id.squeeze(), input_id.squeeze(), mask)\n",
    "        f_pred_id = torch.einsum('...ij,...ij->...ij', pde_loss, mask.expand(3,-1,-1,-1))\n",
    "        f_true_id = torch.zeros_like(f_pred_id)\n",
    "    \n",
    "        loss_id = criterion(f_pred_id, f_true_id)\n",
    "        loss_id.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_id += loss_id.item()\n",
    "    scheduler.step(epoch_loss_id)\n",
    "        \n",
    "    with open(f'{output_dir}/loss.txt', 'a') as f:\n",
    "        f.write(f'{epoch_loss_id}\\n')\n",
    "    \n",
    "    print(f'epoch {epoch} MSE loss: {epoch_loss_id}, lr: ', optimizer.param_groups[0]['lr'])\n",
    "    epoch_loss_list.append(epoch_loss_id)\n",
    "    if epoch%100==0:\n",
    "        if save_model:\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_id_state_dict': optimizer.state_dict(),\n",
    "            'loss_id': epoch_loss_id,\n",
    "            }, f'{output_dir}/model.pth.tar')\n",
    "\n",
    "    if epoch_loss_id<1e6:\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_id_state_dict': optimizer.state_dict(),\n",
    "        'loss_id': epoch_loss_id,\n",
    "        }, f'{output_dir}/model.pth.tar')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.savefig(f'{output_dir}/adadelta_loss_{learning_rate}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'{output_dir}/model.pth.tar')\n",
    "model = DenseED(in_channels=3, out_channels=7, \n",
    "                imsize=100,\n",
    "                blocks=blocks,\n",
    "                growth_rate=16, \n",
    "                init_features=48,\n",
    "                drop_rate=0,\n",
    "                out_activation=None,\n",
    "                upsample='nearest')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "vector_lin = convert.read_nhdr(f'{input_dir}/{brain_id}/{brain_id}_shrinktensor_principal_vector_field.nhdr').to(device).float()\n",
    "mask = convert.read_nhdr(f'{input_dir}/{brain_id}/{brain_id}_shrinktensor_filt_mask.nhdr').to(device).float()\n",
    "\n",
    "u_pred = model(vector_lin.unsqueeze(0))\n",
    "u_pred = u_pred.squeeze()\n",
    "\n",
    "metric_pred_mat = eigen_composite(u_pred)\n",
    "metric_pred_lin = tensors.mat2lin(metric_pred_mat)\n",
    "tensor_pred_mat = torch.inverse(metric_pred_mat)\n",
    "tensor_pred_lin = tensors.mat2lin(tensor_pred_mat)\n",
    "\n",
    "file_name = f'{output_dir}/{brain_id}_learned_metric_final.nhdr'\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.transpose(metric_pred_lin.cpu().detach().numpy(),(3,2,1,0))), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f32f3ba1edf4e91d5019de860c763b8bc58cd2b02b261ced3fefe1a23527a4f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
